{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f03fdf4-004f-4a1b-ab2e-8fa6091f8358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('data/new_tweets_processing/iccs_ntnu_aggregated_data_with_null.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdf0f21-c193-4abf-96e7-12d75e9d6bc8",
   "metadata": {},
   "source": [
    "#sample dataset from other project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "34fda6c0-d4af-4944-9241-2626b20982dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample input from the existing dataset from another project\n",
    "\n",
    "tweet_text = list(data['text'].values)[15]\n",
    "tweet_date = list(data['created_at'].values)[15]\n",
    "tweet_raw_location = list(data['author_location'].values)[15]\n",
    "tweet_language = list(data['language_name'].values)[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d53a6e-5e20-4494-87d4-a8848153a6c1",
   "metadata": {},
   "source": [
    "#processing raw tweet location to get country using Goole Geocode API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47e873d9-b401-4b61-8814-d5c41c4d615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import GoogleV3\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "# Replace 'your_api_key_here' with your actual Google API key\n",
    "API_KEY = 'AIzaSyDQG9qxc2rXxPhwkv9w8kDlJiFlV5O_g20'\n",
    "\n",
    "# Initialize the GoogleV3 geocoder\n",
    "geolocator = GoogleV3(api_key=API_KEY)\n",
    "\n",
    "# Create a rate limiter to avoid overwhelming the server\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
    "\n",
    "# Function to get the country from an address using Google Geocoding API\n",
    "def get_country(address):\n",
    "    try:\n",
    "        location = geocode(address)\n",
    "        if location:\n",
    "            for component in location.raw['address_components']:\n",
    "                if 'country' in component['types']:\n",
    "                    return component['long_name']\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "# Apply the function to the address DataFrame to get the country\n",
    "country = get_country(tweet_raw_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2bf4b9-ab30-4878-a195-82c5be43f96a",
   "metadata": {},
   "source": [
    "#Predicting age, gender of tweet using already trained model on PAN16 dataset (For author profiling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "72f7332a-fe7a-4335-a235-34c4e303c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "#gender prediction\n",
    "model_name = \"gender-classification-pan16-bert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "def predict_gender(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    inputs = {key: value for key, value in inputs.items()}\n",
    "    \n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Perform the prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get the predicted label\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # Map the predicted label to the corresponding gender\n",
    "    labels = [\"female\", \"male\"]\n",
    "    predicted_label = labels[predicted_class]\n",
    "    \n",
    "    return predicted_label\n",
    "    \n",
    "predicted_gender = predict_gender(tweet_text)\n",
    "\n",
    "#age prediction\n",
    "model_name = \"age-classification-pan16-bert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "def predict_age(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    inputs = {key: value for key, value in inputs.items()}\n",
    "    \n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Perform the prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get the predicted label\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # Map the predicted label to the corresponding gender\n",
    "    labels = [\"18-24\", \"25-34\", \"35-49\", \"50-64\", \"65+\"]\n",
    "    predicted_label = labels[predicted_class]\n",
    "    return predicted_label\n",
    "    \n",
    "predicted_age = predict_age(tweet_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f6218-7b37-49fe-9c35-909a7179393e",
   "metadata": {},
   "source": [
    "#Extracting user perceptions from the tweet text using our best evaluated ZSL model from other project results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b81a5df-92f9-4b3a-9d54-8319b3ae4f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4dc5ef8b604e45ae5c796f840d6822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 1/1 [00:07<00:00,  7.21s/it]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from stormtrooper import GenerativeZeroShotClassifier, GenerativeFewShotClassifier\n",
    "\n",
    "#sentiment prediction\n",
    "labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "prompt = \"\"\"\n",
    "### System:\n",
    "You are a helpful sentiment analyzer assistant\n",
    "### User:\n",
    "Your task will be to classify a text document into one\n",
    "of the following sentiment classes: {classes}.\n",
    "Please respond with a single sentiment label that you think fits\n",
    "the document best.\n",
    "Classify the following piece of text:\n",
    "'{X}'\n",
    "### Assistant:\n",
    "\"\"\"\n",
    "model = GenerativeZeroShotClassifier(\"stabilityai/StableBeluga-13B\", prompt=prompt).fit(None, labels) \n",
    "sentiment_prediction = model.predict([tweet_text])\n",
    "sentiment_prediction = sentiment_prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5e61d62-c51b-457c-b62e-f25dce1326aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Variables\n",
      "\n",
      "Tweet Text: Warning of chaos at holiday ports next year under new EU entry rules.\n",
      "Brussels is preparing to roll out its long-awaited Entry/Exit System (EES) which will require all non-EU arrivals to have four fingerprints scanned and a photograph taken.\n",
      "https://t.co/xa5CeDYL9a\n",
      "Tweet Location: Italy\n",
      "Tweet Date: 2021-11-04T11:26:31.000Z\n",
      "\n",
      "\n",
      "\n",
      "Processing Input for Author Profiling\n",
      "Predicted Gender: male\n",
      "Predicted Age: 25-34\n",
      "\n",
      "\n",
      "\n",
      "Processing Input for User Perceptions\n",
      "Predicted Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Variables\\n\")\n",
    "print(\"Tweet Text: \"+ tweet_text)\n",
    "print(\"Tweet Location: \"+ country)\n",
    "print(\"Tweet Date: \"+ tweet_date)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Processing Input for Author Profiling\")\n",
    "print(\"Predicted Gender: \"+predicted_gender)\n",
    "print(\"Predicted Age: \"+predicted_age)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Processing Input for User Perceptions\")\n",
    "print(\"Predicted Sentiment: \"+sentiment_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8728cf3-b58d-45cb-b246-7af506422ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
